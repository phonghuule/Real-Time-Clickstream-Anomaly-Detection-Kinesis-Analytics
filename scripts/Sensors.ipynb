{
  "metadata": {
    "name": "Sensors",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nCreate a sensor_data table describing the format of the data in the stream.\nThe first line tells to Apache Zeppelin to provide a stream SQL environment (%flink.ssql) for the Apache Flink interpreter.\n\nThe first part of the CREATE TABLE statement is familiar to anyone who has used SQL with a database. \nA table is created to store the sensor data in the stream. \nThe WATERMARK option is used to measure progress in the event time, \nas described in the Event Time and Watermarks section of the Apache Flink documentation.\n\nThe second part of the CREATE TABLE statement describes the connector used to receive data in the table \n(for example, kinesis or kafka), the name of the stream, the AWS Region, \nthe overall data format of the stream (such as json or csv), and the syntax used for timestamps (in this case, ISO 8601)\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql\nCREATE TABLE sensor_data (\n    sensor_id INTEGER,\n    current_temperature DOUBLE,\n    status VARCHAR(6),\n    event_time TIMESTAMP(3),\n    WATERMARK FOR event_time AS event_time - INTERVAL \u00275\u0027 SECOND\n)\nPARTITIONED BY (sensor_id)\nWITH (\n    \u0027connector\u0027 \u003d \u0027kinesis\u0027,\n    \u0027stream\u0027 \u003d \u0027my-input-stream\u0027,\n    \u0027aws.region\u0027 \u003d \u0027us-east-1\u0027,\n    \u0027scan.stream.initpos\u0027 \u003d \u0027LATEST\u0027,\n    \u0027format\u0027 \u003d \u0027json\u0027,\n    \u0027json.timestamp-format.standard\u0027 \u003d \u0027ISO-8601\u0027\n)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nSimple SELECT to get all the content of the sensor_data table\nThe first line of the command has a parameter (type\u003dupdate) so that the output of the SELECT, \nwhich is more than one row, is continuously updated when new data arrives.\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\nSELECT * FROM sensor_data;"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nRun the aggregated query explicitly using a SQL syntax using the HOP function in the GROUP BY section of the SELECT statement. \nTo add the time to the output of the select, use the HOP_ROWTIME function.\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\n\nSELECT sensor_data.status,\n       COUNT(*) AS num,\n       AVG(sensor_data.current_temperature) AS avg_current_temperature,\n       HOP_ROWTIME(event_time, INTERVAL \u002710\u0027 second, INTERVAL \u00271\u0027 minute) as hop_time\n  FROM sensor_data\n GROUP BY HOP(event_time, INTERVAL \u002710\u0027 second, INTERVAL \u00271\u0027 minute), sensor_data.status;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nCreate a sensor_state table connected to my-output-stream.\n*/\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql\n\nCREATE TABLE sensor_state (\n    status VARCHAR(6),\n    num INTEGER,\n    avg_current_temperature DOUBLE,\n    hop_time TIMESTAMP(3)\n)\nWITH (\n\u0027connector\u0027 \u003d \u0027kinesis\u0027,\n\u0027stream\u0027 \u003d \u0027my-output-stream\u0027,\n\u0027aws.region\u0027 \u003d \u0027us-east-1\u0027,\n\u0027scan.stream.initpos\u0027 \u003d \u0027LATEST\u0027,\n\u0027format\u0027 \u003d \u0027json\u0027,\n\u0027json.timestamp-format.standard\u0027 \u003d \u0027ISO-8601\u0027);"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nUse this INSERT INTO statement to continuously insert the result of the select into the sensor_state table.\n*/\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.ssql(type\u003dupdate)\n\nINSERT INTO sensor_state\nSELECT sensor_data.status,\n    COUNT(*) AS num,\n    AVG(sensor_data.current_temperature) AS avg_current_temperature,\n    HOP_ROWTIME(event_time, INTERVAL \u002710\u0027 second, INTERVAL \u00271\u0027 minute) as hop_time\nFROM sensor_data\nGROUP BY HOP(event_time, INTERVAL \u002710\u0027 second, INTERVAL \u00271\u0027 minute), sensor_data.status;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "/*\nThe data is also sent to the destination Kinesis data stream (my-output-stream) \nso that it can be used by other applications. \nFor example, the data in the destination stream can be used to update a real-time dashboard\n*/"
    }
  ]
}